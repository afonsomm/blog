[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/pandas-tests/code.html",
    "href": "posts/pandas-tests/code.html",
    "title": "Pandas Tests",
    "section": "",
    "text": "df = pd.DataFrame(range(1000000))\n\n%timeit for _, row in df.iterrows(): ...\n%timeit for row in df.itertuples(): ...\n%timeit df.apply(lambda x: None, axis=1)\n\n20.7 s ± 425 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n357 ms ± 21.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n1.87 s ± 31.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\nitertuples() is the faster way to iterate over the rows of a DF. Besides, it keeps the data types for each column, while the other methods return a row as a pd.Series object, where the data is stored in a np.ndarray, so the data type for every element will be the same."
  },
  {
    "objectID": "posts/pandas-tests/code.html#iterating-over-rows",
    "href": "posts/pandas-tests/code.html#iterating-over-rows",
    "title": "Pandas Tests",
    "section": "",
    "text": "df = pd.DataFrame(range(1000000))\n\n%timeit for _, row in df.iterrows(): ...\n%timeit for row in df.itertuples(): ...\n%timeit df.apply(lambda x: None, axis=1)\n\n20.7 s ± 425 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n357 ms ± 21.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n1.87 s ± 31.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\nitertuples() is the faster way to iterate over the rows of a DF. Besides, it keeps the data types for each column, while the other methods return a row as a pd.Series object, where the data is stored in a np.ndarray, so the data type for every element will be the same."
  },
  {
    "objectID": "posts/fastai-img-classif/fastai-img-classif.html",
    "href": "posts/fastai-img-classif/fastai-img-classif.html",
    "title": "fastai: Image Classifier",
    "section": "",
    "text": "AstroDave, Will Cukierski. (2012). Digit Recognizer. Kaggle. https://kaggle.com/competitions/digit-recognizer\n\n\n\n\nimport numpy as np\nimport pandas as pd\n\n\ntrain_df = pd.read_csv(\"./data/mnist/train.csv\")\ntest_df = pd.read_csv(\"./data/mnist/test.csv\")\n\n\ndisplay(train_df.head(2))\ndisplay(test_df.head(2))\n\n\n\n\n\n\n\n\n\nlabel\npixel0\npixel1\npixel2\npixel3\npixel4\npixel5\npixel6\npixel7\npixel8\n...\npixel774\npixel775\npixel776\npixel777\npixel778\npixel779\npixel780\npixel781\npixel782\npixel783\n\n\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n2 rows × 785 columns\n\n\n\n\n\n\n\n\n\n\n\n\npixel0\npixel1\npixel2\npixel3\npixel4\npixel5\npixel6\npixel7\npixel8\npixel9\n...\npixel774\npixel775\npixel776\npixel777\npixel778\npixel779\npixel780\npixel781\npixel782\npixel783\n\n\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n2 rows × 784 columns\n\n\n\n\n\ndef get_X_y(df: pd.DataFrame, \n            train: bool,\n            frac: float = None,\n            random_state: int = None):\n    \n    if train:\n        sample_df = df.groupby(\"label\").sample(frac=frac, random_state=random_state)\n        X, y = sample_df.iloc[:, 1:].values, sample_df.iloc[:, 0].values\n    else:\n        X = df.values\n        y = None\n    \n    X = X.reshape(-1, 28, 28).astype(np.uint8)\n    return np.moveaxis(np.stack((X,) * 3, axis=1), source=1, destination=-1), y\n\n\ntrain_X, train_y = get_X_y(train_df, train=True, frac=0.05, random_state=0)\ntest_X, _ = get_X_y(test_df, train=False)\n\n\nimport os\n\ntrain_dir = \"./data/mnist/train\"\ntest_dir = \"./data/mnist/test\"\n\nif not os.path.exists(train_dir):\n    os.mkdir(train_dir)\nif not os.path.exists(test_dir):\n    os.mkdir(test_dir)\n    \nfor label in np.unique(train_y):\n    if not os.path.exists(f\"{train_dir}/{label}\"):\n        os.mkdir(f\"{train_dir}/{label}\")\n\n\nfrom PIL import Image\n\nfor i in range(train_X.shape[0]): \n    Image.fromarray(train_X[i]).save(f\"{train_dir}/{train_y[i]}/{i}.jpg\")\n    \nfor i in range(test_X.shape[0]):\n    Image.fromarray(test_X[i]).save(f\"{test_dir}/{i}.jpg\")\n\n\n\n\n\nfrom fastai.vision.all import *\n\n\ndls = DataBlock(blocks = (ImageBlock, CategoryBlock),\n                get_items = get_image_files,\n                get_y = parent_label,\n                splitter = RandomSplitter()\n               ).dataloaders(train_dir)\n\n\ndls.show_batch()\n\n\n\n\n\n\n\n\n\ndls.n\n\n1681\n\n\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(10)\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.799451\n1.431905\n0.459524\n00:07\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.452900\n1.000913\n0.314286\n00:08\n\n\n1\n1.127767\n0.726985\n0.219048\n00:08\n\n\n2\n0.822714\n0.569272\n0.164286\n00:08\n\n\n3\n0.580217\n0.472451\n0.142857\n00:08\n\n\n4\n0.394636\n0.403461\n0.116667\n00:08\n\n\n5\n0.281271\n0.356165\n0.102381\n00:08\n\n\n6\n0.194676\n0.374367\n0.109524\n00:08\n\n\n7\n0.137263\n0.370997\n0.107143\n00:08\n\n\n8\n0.103021\n0.350598\n0.104762\n00:08\n\n\n9\n0.083260\n0.356768\n0.107143\n00:08\n\n\n\n\n\n\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(5, nrows=1, figsize=(17,4))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can correct images annotations or remove them, using the ImageClassifierCleaner. That will show the images for each class (in the train or validation set) where the trained model had the highest classification error. Let’s import the required modules:\n\nfrom fastai.vision.widgets import *\n\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEach time we make a change in one class’s and data set’s (train/validation) samples, by reannotating/removing it, we need to run the following lines before changing to another class or data set, so the changes are applied to the actual data:\n\nfor ind in cleaner.delete(): cleaner.fns[ind].unlink()\nfor ind, cat in cleaner.change(): shutil.move(str(cleaner.fns[ind]), f\"{train_dir}/{cat}\")\n\nIn the end of validating the data, we need to create a new DataLoaders object, to reflect the changes made to the dataset, and retrain the model.\n\ndls = DataBlock(blocks = (ImageBlock, CategoryBlock),\n                get_items = get_image_files,\n                get_y = parent_label,\n                splitter = RandomSplitter()\n               ).dataloaders(train_dir)\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(10)\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.888510\n1.503774\n0.525301\n00:07\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.519504\n1.011998\n0.330120\n00:07\n\n\n1\n1.199548\n0.672037\n0.221687\n00:07\n\n\n2\n0.866976\n0.474139\n0.137349\n00:07\n\n\n3\n0.597648\n0.332307\n0.101205\n00:07\n\n\n4\n0.420963\n0.318540\n0.096386\n00:07\n\n\n5\n0.295351\n0.311173\n0.086747\n00:07\n\n\n6\n0.213994\n0.280651\n0.081928\n00:07\n\n\n7\n0.154817\n0.255272\n0.067470\n00:07\n\n\n8\n0.112886\n0.267510\n0.069880\n00:07\n\n\n9\n0.089455\n0.275279\n0.077108\n00:07\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndls.n\n\n1662\n\n\n\n\n\n\npd.read_csv(\"./data/mnist/sample_submission.csv\").head()\n\n\n\n\n\n\n\n\n\nImageId\nLabel\n\n\n\n\n0\n1\n0\n\n\n1\n2\n0\n\n\n2\n3\n0\n\n\n3\n4\n0\n\n\n4\n5\n0\n\n\n\n\n\n\n\n\n\ntest_dl = dls.test_dl(get_image_files(test_dir))\npreds_probs = learn.get_preds(dl=test_dl)[0]  # probs\n\n\n\n\n\n\n\n\n\npreds = pd.Series(preds_probs.max(axis=1).indices, name=\"Label\")\nids = pd.Series(data=[int(item.name[:-4])+1 for item in test_dl.dataset.items], name=\"ImageId\")\n\n\nsubmission_df = pd.concat((ids, preds), axis=1).sort_values(by=\"ImageId\")\n\n\nsubmission_df.head()\n\n\n\n\n\n\n\n\n\nImageId\nLabel\n\n\n\n\n27898\n1\n2\n\n\n26377\n2\n0\n\n\n24566\n3\n8\n\n\n26165\n4\n9\n\n\n21011\n5\n3\n\n\n\n\n\n\n\n\n\nsubmission_df.to_csv(\"./data/mnist/submission.csv\", index=False)\n\nWe only used 5% of the data for training and validation, to make it faster, so, after iterating this process enough to be confident of our data processing and validation methods, and our model’s architecture and hypeparameters, we would retrain and validate it on the whole dataset.\n\nfrom shutil import rmtree\n\nrmtree(train_dir)\nrmtree(test_dir)"
  },
  {
    "objectID": "posts/fastai-img-classif/fastai-img-classif.html#load-data",
    "href": "posts/fastai-img-classif/fastai-img-classif.html#load-data",
    "title": "fastai: Image Classifier",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\n\n\ntrain_df = pd.read_csv(\"./data/mnist/train.csv\")\ntest_df = pd.read_csv(\"./data/mnist/test.csv\")\n\n\ndisplay(train_df.head(2))\ndisplay(test_df.head(2))\n\n\n\n\n\n\n\n\n\nlabel\npixel0\npixel1\npixel2\npixel3\npixel4\npixel5\npixel6\npixel7\npixel8\n...\npixel774\npixel775\npixel776\npixel777\npixel778\npixel779\npixel780\npixel781\npixel782\npixel783\n\n\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n2 rows × 785 columns\n\n\n\n\n\n\n\n\n\n\n\n\npixel0\npixel1\npixel2\npixel3\npixel4\npixel5\npixel6\npixel7\npixel8\npixel9\n...\npixel774\npixel775\npixel776\npixel777\npixel778\npixel779\npixel780\npixel781\npixel782\npixel783\n\n\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n2 rows × 784 columns\n\n\n\n\n\ndef get_X_y(df: pd.DataFrame, \n            train: bool,\n            frac: float = None,\n            random_state: int = None):\n    \n    if train:\n        sample_df = df.groupby(\"label\").sample(frac=frac, random_state=random_state)\n        X, y = sample_df.iloc[:, 1:].values, sample_df.iloc[:, 0].values\n    else:\n        X = df.values\n        y = None\n    \n    X = X.reshape(-1, 28, 28).astype(np.uint8)\n    return np.moveaxis(np.stack((X,) * 3, axis=1), source=1, destination=-1), y\n\n\ntrain_X, train_y = get_X_y(train_df, train=True, frac=0.05, random_state=0)\ntest_X, _ = get_X_y(test_df, train=False)\n\n\nimport os\n\ntrain_dir = \"./data/mnist/train\"\ntest_dir = \"./data/mnist/test\"\n\nif not os.path.exists(train_dir):\n    os.mkdir(train_dir)\nif not os.path.exists(test_dir):\n    os.mkdir(test_dir)\n    \nfor label in np.unique(train_y):\n    if not os.path.exists(f\"{train_dir}/{label}\"):\n        os.mkdir(f\"{train_dir}/{label}\")\n\n\nfrom PIL import Image\n\nfor i in range(train_X.shape[0]): \n    Image.fromarray(train_X[i]).save(f\"{train_dir}/{train_y[i]}/{i}.jpg\")\n    \nfor i in range(test_X.shape[0]):\n    Image.fromarray(test_X[i]).save(f\"{test_dir}/{i}.jpg\")"
  },
  {
    "objectID": "posts/fastai-img-classif/fastai-img-classif.html#train-model",
    "href": "posts/fastai-img-classif/fastai-img-classif.html#train-model",
    "title": "fastai: Image Classifier",
    "section": "",
    "text": "from fastai.vision.all import *\n\n\ndls = DataBlock(blocks = (ImageBlock, CategoryBlock),\n                get_items = get_image_files,\n                get_y = parent_label,\n                splitter = RandomSplitter()\n               ).dataloaders(train_dir)\n\n\ndls.show_batch()\n\n\n\n\n\n\n\n\n\ndls.n\n\n1681\n\n\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(10)\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.799451\n1.431905\n0.459524\n00:07\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.452900\n1.000913\n0.314286\n00:08\n\n\n1\n1.127767\n0.726985\n0.219048\n00:08\n\n\n2\n0.822714\n0.569272\n0.164286\n00:08\n\n\n3\n0.580217\n0.472451\n0.142857\n00:08\n\n\n4\n0.394636\n0.403461\n0.116667\n00:08\n\n\n5\n0.281271\n0.356165\n0.102381\n00:08\n\n\n6\n0.194676\n0.374367\n0.109524\n00:08\n\n\n7\n0.137263\n0.370997\n0.107143\n00:08\n\n\n8\n0.103021\n0.350598\n0.104762\n00:08\n\n\n9\n0.083260\n0.356768\n0.107143\n00:08\n\n\n\n\n\n\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(5, nrows=1, figsize=(17,4))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can correct images annotations or remove them, using the ImageClassifierCleaner. That will show the images for each class (in the train or validation set) where the trained model had the highest classification error. Let’s import the required modules:\n\nfrom fastai.vision.widgets import *\n\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEach time we make a change in one class’s and data set’s (train/validation) samples, by reannotating/removing it, we need to run the following lines before changing to another class or data set, so the changes are applied to the actual data:\n\nfor ind in cleaner.delete(): cleaner.fns[ind].unlink()\nfor ind, cat in cleaner.change(): shutil.move(str(cleaner.fns[ind]), f\"{train_dir}/{cat}\")\n\nIn the end of validating the data, we need to create a new DataLoaders object, to reflect the changes made to the dataset, and retrain the model.\n\ndls = DataBlock(blocks = (ImageBlock, CategoryBlock),\n                get_items = get_image_files,\n                get_y = parent_label,\n                splitter = RandomSplitter()\n               ).dataloaders(train_dir)\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(10)\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.888510\n1.503774\n0.525301\n00:07\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.519504\n1.011998\n0.330120\n00:07\n\n\n1\n1.199548\n0.672037\n0.221687\n00:07\n\n\n2\n0.866976\n0.474139\n0.137349\n00:07\n\n\n3\n0.597648\n0.332307\n0.101205\n00:07\n\n\n4\n0.420963\n0.318540\n0.096386\n00:07\n\n\n5\n0.295351\n0.311173\n0.086747\n00:07\n\n\n6\n0.213994\n0.280651\n0.081928\n00:07\n\n\n7\n0.154817\n0.255272\n0.067470\n00:07\n\n\n8\n0.112886\n0.267510\n0.069880\n00:07\n\n\n9\n0.089455\n0.275279\n0.077108\n00:07\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndls.n\n\n1662"
  },
  {
    "objectID": "posts/fastai-img-classif/fastai-img-classif.html#test-model",
    "href": "posts/fastai-img-classif/fastai-img-classif.html#test-model",
    "title": "fastai: Image Classifier",
    "section": "",
    "text": "pd.read_csv(\"./data/mnist/sample_submission.csv\").head()\n\n\n\n\n\n\n\n\n\nImageId\nLabel\n\n\n\n\n0\n1\n0\n\n\n1\n2\n0\n\n\n2\n3\n0\n\n\n3\n4\n0\n\n\n4\n5\n0\n\n\n\n\n\n\n\n\n\ntest_dl = dls.test_dl(get_image_files(test_dir))\npreds_probs = learn.get_preds(dl=test_dl)[0]  # probs\n\n\n\n\n\n\n\n\n\npreds = pd.Series(preds_probs.max(axis=1).indices, name=\"Label\")\nids = pd.Series(data=[int(item.name[:-4])+1 for item in test_dl.dataset.items], name=\"ImageId\")\n\n\nsubmission_df = pd.concat((ids, preds), axis=1).sort_values(by=\"ImageId\")\n\n\nsubmission_df.head()\n\n\n\n\n\n\n\n\n\nImageId\nLabel\n\n\n\n\n27898\n1\n2\n\n\n26377\n2\n0\n\n\n24566\n3\n8\n\n\n26165\n4\n9\n\n\n21011\n5\n3\n\n\n\n\n\n\n\n\n\nsubmission_df.to_csv(\"./data/mnist/submission.csv\", index=False)\n\nWe only used 5% of the data for training and validation, to make it faster, so, after iterating this process enough to be confident of our data processing and validation methods, and our model’s architecture and hypeparameters, we would retrain and validate it on the whole dataset.\n\nfrom shutil import rmtree\n\nrmtree(train_dir)\nrmtree(test_dir)"
  },
  {
    "objectID": "posts/fastai-img-classif/fastai-img-classif.html#load-data-1",
    "href": "posts/fastai-img-classif/fastai-img-classif.html#load-data-1",
    "title": "fastai: Image Classifier",
    "section": "Load Data",
    "text": "Load Data\n\nimport pandas as pd\n\n\nlabels = pd.read_csv(\"./data/animals/train-labels.csv\")\n\n\nlabels.head(2)\n\n\n\n\n\n\n\n\n\nid\nantelope_duiker\nbird\nblank\ncivet_genet\nhog\nleopard\nmonkey_prosimian\nrodent\n\n\n\n\n0\nZJ000000\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\nZJ000001\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n\n\n\n\n\n\n\nlabels[\"label\"] = labels.iloc[:, 1:].idxmax(axis=1).values\nlabels = labels[[\"id\", \"label\"]].set_index(\"id\")\n\n\ndisplay(labels.head(2))\nprint(labels.shape)\n\n\n\n\n\n\n\n\n\nlabel\n\n\nid\n\n\n\n\n\nZJ000000\nbird\n\n\nZJ000001\nmonkey_prosimian\n\n\n\n\n\n\n\n\n(16488, 1)\n\n\n\nlabels_sample = labels.groupby(\"label\").sample(frac=0.05)[\"label\"]\n\n\nlabels_sample\n\nid\nZJ009857    antelope_duiker\nZJ006205    antelope_duiker\nZJ015289    antelope_duiker\nZJ002203    antelope_duiker\nZJ008486    antelope_duiker\n                 ...       \nZJ012387             rodent\nZJ008316             rodent\nZJ012197             rodent\nZJ004787             rodent\nZJ007973             rodent\nName: label, Length: 826, dtype: object"
  },
  {
    "objectID": "posts/fastai-img-classif/fastai-img-classif.html#train-model-1",
    "href": "posts/fastai-img-classif/fastai-img-classif.html#train-model-1",
    "title": "fastai: Image Classifier",
    "section": "Train Model",
    "text": "Train Model\n\nfrom fastai.vision.all import *\n\n\ntrain_path = \"./data/animals/train/\"\ntest_path = \"./data/animals/test/\"\n\n\ndef get_items(path):\n\n    path = Path(path)\n    res = []\n\n    for filename in os.listdir(path):\n        if filename[:-4] in labels_sample.index:\n            res.append(path/filename)\n\n    return L(res)\n\n\ndls = DataBlock(blocks=(ImageBlock, CategoryBlock), \n                get_items=get_items,\n                get_y=lambda x: labels_sample.loc[x.name[:-4]], \n                splitter=RandomSplitter(),\n                item_tfms=Resize(128, method=\"squish\"),\n                batch_tfms=[Normalize.from_stats(*imagenet_stats)]\n               ).dataloaders(train_path)\n\n\ndls.show_batch()\n\n\n\n\n\n\n\n\n\ndls.n\n\n661\n\n\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(10)\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n3.050437\n2.190669\n0.696970\n00:10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.883267\n1.707361\n0.551515\n00:12\n\n\n1\n1.671480\n1.513506\n0.436364\n00:12\n\n\n2\n1.359095\n1.500973\n0.460606\n00:12\n\n\n3\n1.100571\n1.569371\n0.448485\n00:11\n\n\n4\n0.877178\n1.688496\n0.460606\n00:11\n\n\n5\n0.698931\n1.693306\n0.478788\n00:11\n\n\n6\n0.563536\n1.697963\n0.430303\n00:11\n\n\n7\n0.463716\n1.748586\n0.448485\n00:11\n\n\n8\n0.376198\n1.744868\n0.448485\n00:11\n\n\n9\n0.311529\n1.747836\n0.454545\n00:11\n\n\n\n\n\n\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(k=5, nrows=1, figsize=(22,4))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom fastai.vision.widgets import *\n\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI can’t see enough to validate the images."
  },
  {
    "objectID": "posts/fastai-img-classif/fastai-img-classif.html#test-model-1",
    "href": "posts/fastai-img-classif/fastai-img-classif.html#test-model-1",
    "title": "fastai: Image Classifier",
    "section": "Test Model",
    "text": "Test Model\n\npd.read_csv(\"./data/animals/sample-submission.csv\").head()\n\n\n\n\n\n\n\n\n\nid\nantelope_duiker\nbird\nblank\ncivet_genet\nhog\nleopard\nmonkey_prosimian\nrodent\n\n\n\n\n0\nZJ016488\n0.048233\n0.189185\n0.044914\n0.199588\n0.106118\n0.132915\n0.166410\n0.112637\n\n\n1\nZJ016489\n0.097078\n0.061400\n0.026409\n0.241530\n0.144344\n0.051780\n0.287811\n0.089648\n\n\n2\nZJ016490\n0.124658\n0.089101\n0.189225\n0.174494\n0.180540\n0.079995\n0.085672\n0.076314\n\n\n3\nZJ016491\n0.109966\n0.048397\n0.055598\n0.323600\n0.322356\n0.063252\n0.008160\n0.068671\n\n\n4\nZJ016492\n0.165742\n0.184610\n0.005431\n0.136806\n0.000389\n0.122078\n0.151521\n0.233423\n\n\n\n\n\n\n\n\n\ntest_dl = dls.test_dl(get_image_files(test_path))\npreds_probs = learn.get_preds(dl=test_dl)[0]\n\n\n\n\n\n\n\n\n\nids = np.array([item.name[:-4] for item in test_dl.dataset.items])\n\n\nlearn.dls.vocab\n\n['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n\n\n\nsubmission_df = pd.DataFrame(data=preds_probs, columns= learn.dls.vocab)\nsubmission_df.insert(0, \"id\", ids)\nsubmission_df.sort_values(by=\"id\", inplace=True)\n\n\nsubmission_df.head()\n\n\n\n\n\n\n\n\n\nid\nantelope_duiker\nbird\nblank\ncivet_genet\nhog\nleopard\nmonkey_prosimian\nrodent\n\n\n\n\n1901\nZJ016488\n0.003612\n6.942989e-04\n0.323665\n5.332318e-01\n0.020963\n0.100759\n1.180175e-02\n0.005273\n\n\n1693\nZJ016489\n0.026071\n8.592082e-02\n0.024220\n4.086171e-03\n0.834774\n0.011074\n1.285491e-02\n0.000999\n\n\n2752\nZJ016490\n0.030828\n5.230120e-02\n0.045449\n1.384969e-01\n0.718519\n0.003206\n7.886172e-03\n0.003315\n\n\n2542\nZJ016491\n0.000002\n8.615297e-08\n0.000002\n3.867934e-07\n0.000002\n0.999990\n9.170705e-07\n0.000002\n\n\n2254\nZJ016492\n0.500051\n1.019086e-02\n0.049266\n3.648468e-02\n0.045658\n0.003554\n3.501456e-01\n0.004649\n\n\n\n\n\n\n\n\n\nsubmission_df.to_csv(\"./data/animals/submission.csv\", index=False)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Pandas Tests\n\n\nBackup of tests with the Pandas data manipulation tool.\n\n\n\nTests\n\n\n\n\n\n\nAfonso Matoso Magalhães\n\n\n\n\n\n\n\n\n\n\n\n\nfastai: Image Classifier\n\n\nApplication of the fastai library to multiple image classification datasets.\n\n\n\ndeep learning\n\n\nimage classification\n\n\n\n\n\n\nAfonso Matoso Magalhães\n\n\n\n\n\n\nNo matching items"
  }
]