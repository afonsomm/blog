[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/pandas-tests/code.html",
    "href": "posts/pandas-tests/code.html",
    "title": "Pandas Tests",
    "section": "",
    "text": "df = pd.DataFrame(range(1000000))\n\n%timeit for _, row in df.iterrows(): ...\n%timeit for row in df.itertuples(): ...\n%timeit df.apply(lambda x: None, axis=1)\n\n20.7 s ± 425 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n357 ms ± 21.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n1.87 s ± 31.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\nitertuples() is the faster way to iterate over the rows of a DF. Besides, it keeps the data types for each column, while the other methods return a row as a pd.Series object, where the data is stored in a np.ndarray, so the data type for every element will be the same."
  },
  {
    "objectID": "posts/pandas-tests/code.html#iterating-over-rows",
    "href": "posts/pandas-tests/code.html#iterating-over-rows",
    "title": "Pandas Tests",
    "section": "",
    "text": "df = pd.DataFrame(range(1000000))\n\n%timeit for _, row in df.iterrows(): ...\n%timeit for row in df.itertuples(): ...\n%timeit df.apply(lambda x: None, axis=1)\n\n20.7 s ± 425 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n357 ms ± 21.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n1.87 s ± 31.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\nitertuples() is the faster way to iterate over the rows of a DF. Besides, it keeps the data types for each column, while the other methods return a row as a pd.Series object, where the data is stored in a np.ndarray, so the data type for every element will be the same."
  },
  {
    "objectID": "posts/fastai-img-classif/fastai-img-classif.html",
    "href": "posts/fastai-img-classif/fastai-img-classif.html",
    "title": "fastai: Image Classifier",
    "section": "",
    "text": "https://course.fast.ai/Lessons/lesson1.html\n\n\n#!pip install -U duckduckgo_search\n\n\nfrom duckduckgo_search import DDGS\nfrom fastcore.all import *\n\nfrom fastdownload import download_url\nfrom fastai.vision.all import *\n\n\n\n\ndef search_images(term, max_images=30):\n    print(f\"Searching for '{term}'\")\n    return L(DDGS().images(keywords=term, max_results=max_images)).itemgot('image')\n\nLet’s start by searching for a bird photo and seeing what kind of result we get. We’ll start by getting URLs from a search:\n\ndata_path = Path(\"./data/lesson1\")\ndata_path.mkdir(parents=True, exist_ok=True)\n\n\nbird_urls = search_images('bird photo', max_images=1)\ndownload_url(bird_urls[0], data_path/\"bird.jpg\", show_progress=False)\nim = Image.open(data_path/\"bird.jpg\")\nim.to_thumb(256,256)\n\nSearching for 'bird photo'\n\n\n\n\n\n\n\n\n\nNow let’s do the same with “forest photos”:\n\nforest_urls = search_images('forest photo', max_images=1)\ndownload_url(forest_urls[0], data_path/\"forest.jpg\", show_progress=False)\nim = Image.open(data_path/\"forest.jpg\")\nim.to_thumb(256,256)\n\nSearching for 'forest photo'\n\n\n\n\n\n\n\n\n\nNow let’s do the same with “cat photo”, “dog photo”, and “wolf photo”:\n\ncat_urls = search_images('cat photo', max_images=1)\ndownload_url(cat_urls[0], data_path/\"cat.jpg\", show_progress=False)\nim = Image.open(data_path/\"cat.jpg\")\nim.to_thumb(256,256)\n\nSearching for 'cat photo'\n\n\n\n\n\n\n\n\n\n\ndog_urls = search_images('dog photo', max_images=1)\ndownload_url(dog_urls[0], data_path/\"dog.jpg\", show_progress=False)\nim = Image.open(data_path/\"dog.jpg\")\nim.to_thumb(256,256)\n\nSearching for 'dog photo'\n\n\n\n\n\n\n\n\n\n\nwolf_urls = search_images('wolf photo', max_images=1)\ndownload_url(wolf_urls[0], data_path/\"wolf.jpg\", show_progress=False)\nim = Image.open(data_path/\"wolf.jpg\")\nim.to_thumb(256,256)\n\nSearching for 'wolf photo'\n\n\n\n\n\n\n\n\n\nOur searches seem to be giving reasonable results, so let’s grab a few examples of each, and save each group of photos to a different folder (I’m also trying to grab a range of lighting conditions here):\n\nsearches = 'forest','bird','cat','dog','wolf'\nimgs_path = data_path/\"imgs\"\nfrom time import sleep\n\nfor o in searches:\n    dest = imgs_path/f\"{o}\"\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} photo sun'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} photo shade'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)\n\nSearching for 'forest photo'\nSearching for 'forest photo sun'\nSearching for 'forest photo shade'\nSearching for 'bird photo'\nSearching for 'bird photo sun'\nSearching for 'bird photo shade'\nSearching for 'cat photo'\nSearching for 'cat photo sun'\nSearching for 'cat photo shade'\nSearching for 'dog photo'\nSearching for 'dog photo sun'\nSearching for 'dog photo shade'\nSearching for 'wolf photo'\nSearching for 'wolf photo sun'\nSearching for 'wolf photo shade'\n\n\n\n\n\nSome photos might not download correctly which could cause our model training to fail, so we’ll remove them:\n\nfailed = verify_images(get_image_files(imgs_path))\nfailed.map(Path.unlink)\nlen(failed)\n\n14\n\n\nTo train a model, we’ll need DataLoaders, which is an object that contains a training set (the images used to create a model) and a validation set (the images used to check the accuracy of a model – not used during training). In fastai we can create that easily using a DataBlock, and view sample images from it:\n\ndls = DataBlock(blocks=(ImageBlock, CategoryBlock), \n                get_items=get_image_files, \n                splitter=RandomSplitter(valid_pct=0.2, seed=0),\n                get_y=parent_label,\n                item_tfms=[Resize(192, method=\"squish\")]\n               ).dataloaders(imgs_path)\n\ndls.show_batch(max_n=6)\n\n\n\n\n\n\n\n\nHere what each of the DataBlock parameters means:\nblocks=(ImageBlock, CategoryBlock), - The inputs to our model are images, and the outputs are categories (in this case, “forest”, “bird”, “cat”, “dog” or “wolf”).\nget_items=get_image_files, - To find all the inputs to our model, run the get_image_files function (which returns a list of all image files in a path).\nsplitter=RandomSplitter(valid_pct=0.2, seed=42), - Split the data into training and validation sets randomly, using 20% of the data for the validation set.\nget_y=parent_label, - The labels (y values) is the name of the parent of each file (i.e. the name of the folder they’re in, which will be “forest”, “bird”, “cat”, “dog” or “wolf”).\nitem_tfms=[Resize(192, method='squish')] - Before training, resize each image to 192x192 pixels by “squishing” it (as opposed to cropping it).\nNow we’re ready to train our model. The fastest widely used computer vision model is resnet18. You can train this in a few minutes, even on a CPU! (On a GPU, it generally takes under 10 seconds…)\nfastai comes with a helpful fine_tune() method which automatically uses best practices for fine tuning a pre-trained model, so we’ll use that.\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.004911\n0.474476\n0.192771\n00:49\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.505954\n0.225417\n0.096386\n00:48\n\n\n1\n0.326397\n0.217455\n0.084337\n00:48\n\n\n2\n0.236130\n0.237563\n0.096386\n00:48\n\n\n\n\n\n\n“Fine-tuning” a model means that we’re starting with a model someone else has trained using some other dataset (called the pretrained model), and adjusting the weights a little bit so that the model learns to recognise your particular dataset. In this case, the pretrained model was trained to recognise photos in imagenet, and widely-used computer vision dataset with images covering 1000 categories) For details on fine-tuning and why it’s important, check out the free free fast.ai course.\n\n\n\nLet’s see what our model thinks about that bird we downloaded at the start:\n\nis_bird,_,probs = learn.predict(PILImage.create(data_path/'bird.jpg'))\nprint(f\"This is a: {is_bird}.\")\nprint(f\"Probability it's a bird: {probs[0]:.4f}\")\n\n\n\n\n\n\n\n\nThis is a: bird.\nProbability it's a bird: 0.9998\n\n\nGood job, resnet18. :)\nSo, as you see, in the space of a few years, creating computer vision classification models has gone from “so hard it’s a joke” to “trivially easy and free”!\nIt’s not just in computer vision. Thanks to deep learning, computers can now do many things which seemed impossible just a few years ago, including creating amazing artworks, and explaining jokes. It’s moving so fast that even experts in the field have trouble predicting how it’s going to impact society in the coming years.\nOne thing is clear – it’s important that we all do our best to understand this technology, because otherwise we’ll get left behind!"
  },
  {
    "objectID": "posts/fastai-img-classif/fastai-img-classif.html#load-data",
    "href": "posts/fastai-img-classif/fastai-img-classif.html#load-data",
    "title": "fastai: Image Classifier",
    "section": "",
    "text": "def search_images(term, max_images=30):\n    print(f\"Searching for '{term}'\")\n    return L(DDGS().images(keywords=term, max_results=max_images)).itemgot('image')\n\nLet’s start by searching for a bird photo and seeing what kind of result we get. We’ll start by getting URLs from a search:\n\ndata_path = Path(\"./data/lesson1\")\ndata_path.mkdir(parents=True, exist_ok=True)\n\n\nbird_urls = search_images('bird photo', max_images=1)\ndownload_url(bird_urls[0], data_path/\"bird.jpg\", show_progress=False)\nim = Image.open(data_path/\"bird.jpg\")\nim.to_thumb(256,256)\n\nSearching for 'bird photo'\n\n\n\n\n\n\n\n\n\nNow let’s do the same with “forest photos”:\n\nforest_urls = search_images('forest photo', max_images=1)\ndownload_url(forest_urls[0], data_path/\"forest.jpg\", show_progress=False)\nim = Image.open(data_path/\"forest.jpg\")\nim.to_thumb(256,256)\n\nSearching for 'forest photo'\n\n\n\n\n\n\n\n\n\nNow let’s do the same with “cat photo”, “dog photo”, and “wolf photo”:\n\ncat_urls = search_images('cat photo', max_images=1)\ndownload_url(cat_urls[0], data_path/\"cat.jpg\", show_progress=False)\nim = Image.open(data_path/\"cat.jpg\")\nim.to_thumb(256,256)\n\nSearching for 'cat photo'\n\n\n\n\n\n\n\n\n\n\ndog_urls = search_images('dog photo', max_images=1)\ndownload_url(dog_urls[0], data_path/\"dog.jpg\", show_progress=False)\nim = Image.open(data_path/\"dog.jpg\")\nim.to_thumb(256,256)\n\nSearching for 'dog photo'\n\n\n\n\n\n\n\n\n\n\nwolf_urls = search_images('wolf photo', max_images=1)\ndownload_url(wolf_urls[0], data_path/\"wolf.jpg\", show_progress=False)\nim = Image.open(data_path/\"wolf.jpg\")\nim.to_thumb(256,256)\n\nSearching for 'wolf photo'\n\n\n\n\n\n\n\n\n\nOur searches seem to be giving reasonable results, so let’s grab a few examples of each, and save each group of photos to a different folder (I’m also trying to grab a range of lighting conditions here):\n\nsearches = 'forest','bird','cat','dog','wolf'\nimgs_path = data_path/\"imgs\"\nfrom time import sleep\n\nfor o in searches:\n    dest = imgs_path/f\"{o}\"\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images(f'{o} photo'))\n    sleep(10)  # Pause between searches to avoid over-loading server\n    download_images(dest, urls=search_images(f'{o} photo sun'))\n    sleep(10)\n    download_images(dest, urls=search_images(f'{o} photo shade'))\n    sleep(10)\n    resize_images(path/o, max_size=400, dest=path/o)\n\nSearching for 'forest photo'\nSearching for 'forest photo sun'\nSearching for 'forest photo shade'\nSearching for 'bird photo'\nSearching for 'bird photo sun'\nSearching for 'bird photo shade'\nSearching for 'cat photo'\nSearching for 'cat photo sun'\nSearching for 'cat photo shade'\nSearching for 'dog photo'\nSearching for 'dog photo sun'\nSearching for 'dog photo shade'\nSearching for 'wolf photo'\nSearching for 'wolf photo sun'\nSearching for 'wolf photo shade'"
  },
  {
    "objectID": "posts/fastai-img-classif/fastai-img-classif.html#train-model",
    "href": "posts/fastai-img-classif/fastai-img-classif.html#train-model",
    "title": "fastai: Image Classifier",
    "section": "",
    "text": "Some photos might not download correctly which could cause our model training to fail, so we’ll remove them:\n\nfailed = verify_images(get_image_files(imgs_path))\nfailed.map(Path.unlink)\nlen(failed)\n\n14\n\n\nTo train a model, we’ll need DataLoaders, which is an object that contains a training set (the images used to create a model) and a validation set (the images used to check the accuracy of a model – not used during training). In fastai we can create that easily using a DataBlock, and view sample images from it:\n\ndls = DataBlock(blocks=(ImageBlock, CategoryBlock), \n                get_items=get_image_files, \n                splitter=RandomSplitter(valid_pct=0.2, seed=0),\n                get_y=parent_label,\n                item_tfms=[Resize(192, method=\"squish\")]\n               ).dataloaders(imgs_path)\n\ndls.show_batch(max_n=6)\n\n\n\n\n\n\n\n\nHere what each of the DataBlock parameters means:\nblocks=(ImageBlock, CategoryBlock), - The inputs to our model are images, and the outputs are categories (in this case, “forest”, “bird”, “cat”, “dog” or “wolf”).\nget_items=get_image_files, - To find all the inputs to our model, run the get_image_files function (which returns a list of all image files in a path).\nsplitter=RandomSplitter(valid_pct=0.2, seed=42), - Split the data into training and validation sets randomly, using 20% of the data for the validation set.\nget_y=parent_label, - The labels (y values) is the name of the parent of each file (i.e. the name of the folder they’re in, which will be “forest”, “bird”, “cat”, “dog” or “wolf”).\nitem_tfms=[Resize(192, method='squish')] - Before training, resize each image to 192x192 pixels by “squishing” it (as opposed to cropping it).\nNow we’re ready to train our model. The fastest widely used computer vision model is resnet18. You can train this in a few minutes, even on a CPU! (On a GPU, it generally takes under 10 seconds…)\nfastai comes with a helpful fine_tune() method which automatically uses best practices for fine tuning a pre-trained model, so we’ll use that.\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.004911\n0.474476\n0.192771\n00:49\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.505954\n0.225417\n0.096386\n00:48\n\n\n1\n0.326397\n0.217455\n0.084337\n00:48\n\n\n2\n0.236130\n0.237563\n0.096386\n00:48\n\n\n\n\n\n\n“Fine-tuning” a model means that we’re starting with a model someone else has trained using some other dataset (called the pretrained model), and adjusting the weights a little bit so that the model learns to recognise your particular dataset. In this case, the pretrained model was trained to recognise photos in imagenet, and widely-used computer vision dataset with images covering 1000 categories) For details on fine-tuning and why it’s important, check out the free free fast.ai course."
  },
  {
    "objectID": "posts/fastai-img-classif/fastai-img-classif.html#test-model",
    "href": "posts/fastai-img-classif/fastai-img-classif.html#test-model",
    "title": "fastai: Image Classifier",
    "section": "",
    "text": "Let’s see what our model thinks about that bird we downloaded at the start:\n\nis_bird,_,probs = learn.predict(PILImage.create(data_path/'bird.jpg'))\nprint(f\"This is a: {is_bird}.\")\nprint(f\"Probability it's a bird: {probs[0]:.4f}\")\n\n\n\n\n\n\n\n\nThis is a: bird.\nProbability it's a bird: 0.9998\n\n\nGood job, resnet18. :)\nSo, as you see, in the space of a few years, creating computer vision classification models has gone from “so hard it’s a joke” to “trivially easy and free”!\nIt’s not just in computer vision. Thanks to deep learning, computers can now do many things which seemed impossible just a few years ago, including creating amazing artworks, and explaining jokes. It’s moving so fast that even experts in the field have trouble predicting how it’s going to impact society in the coming years.\nOne thing is clear – it’s important that we all do our best to understand this technology, because otherwise we’ll get left behind!"
  },
  {
    "objectID": "posts/fastai-img-classif/fastai-img-classif.html#load-data-1",
    "href": "posts/fastai-img-classif/fastai-img-classif.html#load-data-1",
    "title": "fastai: Image Classifier",
    "section": "Load Data",
    "text": "Load Data\n\nimport numpy as np\nimport pandas as pd\n\n\ntrain_df = pd.read_csv(\"./data/mnist/train.csv\")\ntest_df = pd.read_csv(\"./data/mnist/test.csv\")\n\n\ndisplay(train_df.head(2))\ndisplay(test_df.head(2))\n\n\n\n\n\n\n\n\n\nlabel\npixel0\npixel1\npixel2\npixel3\npixel4\npixel5\npixel6\npixel7\npixel8\n...\npixel774\npixel775\npixel776\npixel777\npixel778\npixel779\npixel780\npixel781\npixel782\npixel783\n\n\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n2 rows × 785 columns\n\n\n\n\n\n\n\n\n\n\n\n\npixel0\npixel1\npixel2\npixel3\npixel4\npixel5\npixel6\npixel7\npixel8\npixel9\n...\npixel774\npixel775\npixel776\npixel777\npixel778\npixel779\npixel780\npixel781\npixel782\npixel783\n\n\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n2 rows × 784 columns\n\n\n\n\n\ndef get_X_y(df: pd.DataFrame, \n            train: bool,\n            frac: float = None,\n            random_state: int = None):\n    \n    if train:\n        sample_df = df.groupby(\"label\").sample(frac=frac, random_state=random_state)\n        X, y = sample_df.iloc[:, 1:].values, sample_df.iloc[:, 0].values\n    else:\n        X = df.values\n        y = None\n    \n    X = X.reshape(-1, 28, 28).astype(np.uint8)\n    return np.moveaxis(np.stack((X,) * 3, axis=1), source=1, destination=-1), y\n\n\ntrain_X, train_y = get_X_y(train_df, train=True, frac=0.05, random_state=0)\ntest_X, _ = get_X_y(test_df, train=False)\n\n\nimport os\n\ntrain_dir = \"./data/mnist/train\"\ntest_dir = \"./data/mnist/test\"\n\nif not os.path.exists(train_dir):\n    os.mkdir(train_dir)\nif not os.path.exists(test_dir):\n    os.mkdir(test_dir)\n    \nfor label in np.unique(train_y):\n    if not os.path.exists(f\"{train_dir}/{label}\"):\n        os.mkdir(f\"{train_dir}/{label}\")\n\n\nfrom PIL import Image\n\nfor i in range(train_X.shape[0]): \n    Image.fromarray(train_X[i]).save(f\"{train_dir}/{train_y[i]}/{i}.jpg\")\n    \nfor i in range(test_X.shape[0]):\n    Image.fromarray(test_X[i]).save(f\"{test_dir}/{i}.jpg\")"
  },
  {
    "objectID": "posts/fastai-img-classif/fastai-img-classif.html#train-model-1",
    "href": "posts/fastai-img-classif/fastai-img-classif.html#train-model-1",
    "title": "fastai: Image Classifier",
    "section": "Train Model",
    "text": "Train Model\n\nfrom fastai.vision.all import *\n\n\ndls = DataBlock(blocks = (ImageBlock, CategoryBlock),\n                get_items = get_image_files,\n                get_y = parent_label,\n                splitter = RandomSplitter()\n               ).dataloaders(train_dir)\n\n\ndls.show_batch()\n\n\n\n\n\n\n\n\n\ndls.n\n\n1681\n\n\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(10)\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.799451\n1.431905\n0.459524\n00:07\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.452900\n1.000913\n0.314286\n00:08\n\n\n1\n1.127767\n0.726985\n0.219048\n00:08\n\n\n2\n0.822714\n0.569272\n0.164286\n00:08\n\n\n3\n0.580217\n0.472451\n0.142857\n00:08\n\n\n4\n0.394636\n0.403461\n0.116667\n00:08\n\n\n5\n0.281271\n0.356165\n0.102381\n00:08\n\n\n6\n0.194676\n0.374367\n0.109524\n00:08\n\n\n7\n0.137263\n0.370997\n0.107143\n00:08\n\n\n8\n0.103021\n0.350598\n0.104762\n00:08\n\n\n9\n0.083260\n0.356768\n0.107143\n00:08\n\n\n\n\n\n\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(5, nrows=1, figsize=(17,4))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can correct images annotations or remove them, using the ImageClassifierCleaner. That will show the images for each class (in the train or validation set) where the trained model had the highest classification error. Let’s import the required modules:\n\nfrom fastai.vision.widgets import *\n\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEach time we make a change in one class’s and data set’s (train/validation) samples, by reannotating/removing it, we need to run the following lines before changing to another class or data set, so the changes are applied to the actual data:\n\nfor ind in cleaner.delete(): cleaner.fns[ind].unlink()\nfor ind, cat in cleaner.change(): shutil.move(str(cleaner.fns[ind]), f\"{train_dir}/{cat}\")\n\nIn the end of validating the data, we need to create a new DataLoaders object, to reflect the changes made to the dataset, and retrain the model.\n\ndls = DataBlock(blocks = (ImageBlock, CategoryBlock),\n                get_items = get_image_files,\n                get_y = parent_label,\n                splitter = RandomSplitter()\n               ).dataloaders(train_dir)\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(10)\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n2.888510\n1.503774\n0.525301\n00:07\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.519504\n1.011998\n0.330120\n00:07\n\n\n1\n1.199548\n0.672037\n0.221687\n00:07\n\n\n2\n0.866976\n0.474139\n0.137349\n00:07\n\n\n3\n0.597648\n0.332307\n0.101205\n00:07\n\n\n4\n0.420963\n0.318540\n0.096386\n00:07\n\n\n5\n0.295351\n0.311173\n0.086747\n00:07\n\n\n6\n0.213994\n0.280651\n0.081928\n00:07\n\n\n7\n0.154817\n0.255272\n0.067470\n00:07\n\n\n8\n0.112886\n0.267510\n0.069880\n00:07\n\n\n9\n0.089455\n0.275279\n0.077108\n00:07\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndls.n\n\n1662"
  },
  {
    "objectID": "posts/fastai-img-classif/fastai-img-classif.html#test-model-1",
    "href": "posts/fastai-img-classif/fastai-img-classif.html#test-model-1",
    "title": "fastai: Image Classifier",
    "section": "Test Model",
    "text": "Test Model\n\npd.read_csv(\"./data/mnist/sample_submission.csv\").head()\n\n\n\n\n\n\n\n\n\nImageId\nLabel\n\n\n\n\n0\n1\n0\n\n\n1\n2\n0\n\n\n2\n3\n0\n\n\n3\n4\n0\n\n\n4\n5\n0\n\n\n\n\n\n\n\n\n\ntest_dl = dls.test_dl(get_image_files(test_dir))\npreds_probs = learn.get_preds(dl=test_dl)[0]  # probs\n\n\n\n\n\n\n\n\n\npreds = pd.Series(preds_probs.max(axis=1).indices, name=\"Label\")\nids = pd.Series(data=[int(item.name[:-4])+1 for item in test_dl.dataset.items], name=\"ImageId\")\n\n\nsubmission_df = pd.concat((ids, preds), axis=1).sort_values(by=\"ImageId\")\n\n\nsubmission_df.head()\n\n\n\n\n\n\n\n\n\nImageId\nLabel\n\n\n\n\n27898\n1\n2\n\n\n26377\n2\n0\n\n\n24566\n3\n8\n\n\n26165\n4\n9\n\n\n21011\n5\n3\n\n\n\n\n\n\n\n\n\nsubmission_df.to_csv(\"./data/mnist/submission.csv\", index=False)\n\nWe only used 5% of the data for training and validation, to make it faster, so, after iterating this process enough to be confident of our data processing and validation methods, and our model’s architecture and hypeparameters, we would retrain and validate it on the whole dataset.\n\nfrom shutil import rmtree\n\nrmtree(train_dir)\nrmtree(test_dir)"
  },
  {
    "objectID": "posts/fastai-img-classif/fastai-img-classif.html#load-data-2",
    "href": "posts/fastai-img-classif/fastai-img-classif.html#load-data-2",
    "title": "fastai: Image Classifier",
    "section": "Load Data",
    "text": "Load Data\n\nimport pandas as pd\n\n\nlabels = pd.read_csv(\"./data/animals/train-labels.csv\")\n\n\nlabels.head(2)\n\n\n\n\n\n\n\n\n\nid\nantelope_duiker\nbird\nblank\ncivet_genet\nhog\nleopard\nmonkey_prosimian\nrodent\n\n\n\n\n0\nZJ000000\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1\nZJ000001\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.0\n0.0\n\n\n\n\n\n\n\n\n\nlabels[\"label\"] = labels.iloc[:, 1:].idxmax(axis=1).values\nlabels = labels[[\"id\", \"label\"]].set_index(\"id\")\n\n\ndisplay(labels.head(2))\nprint(labels.shape)\n\n\n\n\n\n\n\n\n\nlabel\n\n\nid\n\n\n\n\n\nZJ000000\nbird\n\n\nZJ000001\nmonkey_prosimian\n\n\n\n\n\n\n\n\n(16488, 1)\n\n\n\nlabels_sample = labels.groupby(\"label\").sample(frac=0.05)[\"label\"]\n\n\nlabels_sample\n\nid\nZJ009857    antelope_duiker\nZJ006205    antelope_duiker\nZJ015289    antelope_duiker\nZJ002203    antelope_duiker\nZJ008486    antelope_duiker\n                 ...       \nZJ012387             rodent\nZJ008316             rodent\nZJ012197             rodent\nZJ004787             rodent\nZJ007973             rodent\nName: label, Length: 826, dtype: object"
  },
  {
    "objectID": "posts/fastai-img-classif/fastai-img-classif.html#train-model-2",
    "href": "posts/fastai-img-classif/fastai-img-classif.html#train-model-2",
    "title": "fastai: Image Classifier",
    "section": "Train Model",
    "text": "Train Model\n\nfrom fastai.vision.all import *\n\n\ntrain_path = \"./data/animals/train/\"\ntest_path = \"./data/animals/test/\"\n\n\ndef get_items(path):\n\n    path = Path(path)\n    res = []\n\n    for filename in os.listdir(path):\n        if filename[:-4] in labels_sample.index:\n            res.append(path/filename)\n\n    return L(res)\n\n\ndls = DataBlock(blocks=(ImageBlock, CategoryBlock), \n                get_items=get_items,\n                get_y=lambda x: labels_sample.loc[x.name[:-4]], \n                splitter=RandomSplitter(),\n                item_tfms=Resize(128, method=\"squish\"),\n                batch_tfms=[Normalize.from_stats(*imagenet_stats)]\n               ).dataloaders(train_path)\n\n\ndls.show_batch()\n\n\n\n\n\n\n\n\n\ndls.n\n\n661\n\n\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(10)\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n3.050437\n2.190669\n0.696970\n00:10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.883267\n1.707361\n0.551515\n00:12\n\n\n1\n1.671480\n1.513506\n0.436364\n00:12\n\n\n2\n1.359095\n1.500973\n0.460606\n00:12\n\n\n3\n1.100571\n1.569371\n0.448485\n00:11\n\n\n4\n0.877178\n1.688496\n0.460606\n00:11\n\n\n5\n0.698931\n1.693306\n0.478788\n00:11\n\n\n6\n0.563536\n1.697963\n0.430303\n00:11\n\n\n7\n0.463716\n1.748586\n0.448485\n00:11\n\n\n8\n0.376198\n1.744868\n0.448485\n00:11\n\n\n9\n0.311529\n1.747836\n0.454545\n00:11\n\n\n\n\n\n\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(k=5, nrows=1, figsize=(22,4))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfrom fastai.vision.widgets import *\n\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI can’t see enough to validate the images."
  },
  {
    "objectID": "posts/fastai-img-classif/fastai-img-classif.html#test-model-2",
    "href": "posts/fastai-img-classif/fastai-img-classif.html#test-model-2",
    "title": "fastai: Image Classifier",
    "section": "Test Model",
    "text": "Test Model\n\npd.read_csv(\"./data/animals/sample-submission.csv\").head()\n\n\n\n\n\n\n\n\n\nid\nantelope_duiker\nbird\nblank\ncivet_genet\nhog\nleopard\nmonkey_prosimian\nrodent\n\n\n\n\n0\nZJ016488\n0.048233\n0.189185\n0.044914\n0.199588\n0.106118\n0.132915\n0.166410\n0.112637\n\n\n1\nZJ016489\n0.097078\n0.061400\n0.026409\n0.241530\n0.144344\n0.051780\n0.287811\n0.089648\n\n\n2\nZJ016490\n0.124658\n0.089101\n0.189225\n0.174494\n0.180540\n0.079995\n0.085672\n0.076314\n\n\n3\nZJ016491\n0.109966\n0.048397\n0.055598\n0.323600\n0.322356\n0.063252\n0.008160\n0.068671\n\n\n4\nZJ016492\n0.165742\n0.184610\n0.005431\n0.136806\n0.000389\n0.122078\n0.151521\n0.233423\n\n\n\n\n\n\n\n\n\ntest_dl = dls.test_dl(get_image_files(test_path))\npreds_probs = learn.get_preds(dl=test_dl)[0]\n\n\n\n\n\n\n\n\n\nids = np.array([item.name[:-4] for item in test_dl.dataset.items])\n\n\nlearn.dls.vocab\n\n['antelope_duiker', 'bird', 'blank', 'civet_genet', 'hog', 'leopard', 'monkey_prosimian', 'rodent']\n\n\n\nsubmission_df = pd.DataFrame(data=preds_probs, columns= learn.dls.vocab)\nsubmission_df.insert(0, \"id\", ids)\nsubmission_df.sort_values(by=\"id\", inplace=True)\n\n\nsubmission_df.head()\n\n\n\n\n\n\n\n\n\nid\nantelope_duiker\nbird\nblank\ncivet_genet\nhog\nleopard\nmonkey_prosimian\nrodent\n\n\n\n\n1901\nZJ016488\n0.003612\n6.942989e-04\n0.323665\n5.332318e-01\n0.020963\n0.100759\n1.180175e-02\n0.005273\n\n\n1693\nZJ016489\n0.026071\n8.592082e-02\n0.024220\n4.086171e-03\n0.834774\n0.011074\n1.285491e-02\n0.000999\n\n\n2752\nZJ016490\n0.030828\n5.230120e-02\n0.045449\n1.384969e-01\n0.718519\n0.003206\n7.886172e-03\n0.003315\n\n\n2542\nZJ016491\n0.000002\n8.615297e-08\n0.000002\n3.867934e-07\n0.000002\n0.999990\n9.170705e-07\n0.000002\n\n\n2254\nZJ016492\n0.500051\n1.019086e-02\n0.049266\n3.648468e-02\n0.045658\n0.003554\n3.501456e-01\n0.004649\n\n\n\n\n\n\n\n\n\nsubmission_df.to_csv(\"./data/animals/submission.csv\", index=False)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Pandas Tests\n\n\nBackup of tests with the Pandas data manipulation tool.\n\n\n\nTests\n\n\n\n\n\n\nAfonso Matoso Magalhães\n\n\n\n\n\n\n\n\n\n\n\n\nfastai: Image Classifier\n\n\nApplication of the fastai library to multiple image classification datasets.\n\n\n\ndeep learning\n\n\nimage classification\n\n\n\n\n\n\nAfonso Matoso Magalhães\n\n\n\n\n\n\nNo matching items"
  }
]