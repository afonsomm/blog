[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/pandas-tests/code.html",
    "href": "posts/pandas-tests/code.html",
    "title": "Pandas Tests",
    "section": "",
    "text": "df = pd.DataFrame(range(1000000))\n\n%timeit for _, row in df.iterrows(): ...\n%timeit for row in df.itertuples(): ...\n%timeit df.apply(lambda x: None, axis=1)\n\n20.7 s ± 425 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n357 ms ± 21.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n1.87 s ± 31.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\nitertuples() is the faster way to iterate over the rows of a DF. Besides, it keeps the data types for each column, while the other methods return a row as a pd.Series object, where the data is stored in a np.ndarray, so the data type for every element will be the same."
  },
  {
    "objectID": "posts/pandas-tests/code.html#iterating-over-rows",
    "href": "posts/pandas-tests/code.html#iterating-over-rows",
    "title": "Pandas Tests",
    "section": "",
    "text": "df = pd.DataFrame(range(1000000))\n\n%timeit for _, row in df.iterrows(): ...\n%timeit for row in df.itertuples(): ...\n%timeit df.apply(lambda x: None, axis=1)\n\n20.7 s ± 425 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n357 ms ± 21.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n1.87 s ± 31.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n\n\n\nitertuples() is the faster way to iterate over the rows of a DF. Besides, it keeps the data types for each column, while the other methods return a row as a pd.Series object, where the data is stored in a np.ndarray, so the data type for every element will be the same."
  },
  {
    "objectID": "posts/fastai-img-classif/code.html",
    "href": "posts/fastai-img-classif/code.html",
    "title": "fastai: Image Classifier",
    "section": "",
    "text": "This post uses the fastai library to classify images of the MNIST dataset (https://www.kaggle.com/competitions/digit-recognizer/data).\n\nLoad Data\n\nimport numpy as np\nimport pandas as pd\n\n\ntrain_df = pd.read_csv(\"./data/train.csv\")\ntest_df = pd.read_csv(\"./data/test.csv\")\n\n\ndisplay(train_df.head(2))\ndisplay(test_df.head(2))\n\n\n\n\n\n\n\n\n\nlabel\npixel0\npixel1\npixel2\npixel3\npixel4\npixel5\npixel6\npixel7\npixel8\n...\npixel774\npixel775\npixel776\npixel777\npixel778\npixel779\npixel780\npixel781\npixel782\npixel783\n\n\n\n\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n2 rows × 785 columns\n\n\n\n\n\n\n\n\n\n\n\n\npixel0\npixel1\npixel2\npixel3\npixel4\npixel5\npixel6\npixel7\npixel8\npixel9\n...\npixel774\npixel775\npixel776\npixel777\npixel778\npixel779\npixel780\npixel781\npixel782\npixel783\n\n\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n2 rows × 784 columns\n\n\n\n\n\ndef get_X_y(df: pd.DataFrame, \n            train: bool,\n            frac: float = None,\n            random_state: int = None):\n    \n    if train:\n        sample_df = df.groupby(\"label\").sample(frac=frac, random_state=random_state)\n        X, y = sample_df.iloc[:, 1:].values, sample_df.iloc[:, 0].values\n    else:\n        X = df.values\n        y = None\n    \n    X = X.reshape(-1, 28, 28).astype(np.uint8)\n    return np.moveaxis(np.stack((X,) * 3, axis=1), source=1, destination=-1), y\n\n\ntrain_X, train_y = get_X_y(train_df, train=True, frac=0.05, random_state=0)\ntest_X, _ = get_X_y(test_df, train=False)\n\n\nimport os\n\ntrain_dir = \"./data/train\"\ntest_dir = \"./data/test\"\n\nif not os.path.exists(train_dir):\n    os.mkdir(train_dir)\nif not os.path.exists(test_dir):\n    os.mkdir(test_dir)\n    \nfor label in np.unique(train_y):\n    if not os.path.exists(f\"{train_dir}/{label}\"):\n        os.mkdir(f\"{train_dir}/{label}\")\n\n\nfrom PIL import Image\n\n\nfor i in range(train_X.shape[0]): \n    Image.fromarray(train_X[i]).save(f\"{train_dir}/{train_y[i]}/{i}.jpg\")\n    \nfor i in range(test_X.shape[0]):\n    Image.fromarray(test_X[i]).save(f\"{test_dir}/{i}.jpg\")\n\n\n\nTrain Model\n\nfrom fastai.vision.all import *\n\n\ndls = DataBlock(blocks = (ImageBlock, CategoryBlock),\n                get_items = get_image_files,\n                get_y = parent_label,\n                splitter = RandomSplitter(valid_pct = 0.5, seed = 0)\n               ).dataloaders(train_dir)\n\n\ndls.show_batch()\n\n\n\n\n\n\n\n\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n3.052123\n1.864471\n0.635238\n00:08\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.656031\n1.243780\n0.422857\n00:06\n\n\n1\n1.263025\n0.869192\n0.276190\n00:06\n\n\n2\n0.937062\n0.807364\n0.245714\n00:06\n\n\n\n\n\n\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(5, nrows=1, figsize=(17,4))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can correct images annotations or remove them, using the ImageClassifierCleaner. That will show the images for each class (in the train or validation set) where the trained model had the highest classification error. Let’s import the required modules:\n\nfrom fastai.vision.widgets import *\n\n\ncleaner = ImageClassifierCleaner(learn)\ncleaner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEach time we make a change in one class’s and data set’s (train/validation) samples, by reannotating/removing it, we need to run the following lines before changing to another class or data set, so the changes are applied to the actual data:\n\nfor ind in cleaner.delete(): cleaner.fns[ind].unlink()\nfor ind, cat in cleaner.change(): shutil.move(str(cleaner.fns[ind]), f\"{train_dir}/{cat}\")\n\nIn the end of validating the data, we need to create a new DataLoaders object, to reflect the changes made to the dataset, and retrain the model.\n\ndls = DataBlock(blocks = (ImageBlock, CategoryBlock),\n                get_items = get_image_files,\n                get_y = parent_label,\n                splitter = RandomSplitter(valid_pct = 0.5, seed = 0)\n               ).dataloaders(train_dir)\n\nlearn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(3)\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n3.235463\n1.952349\n0.681602\n00:05\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n1.616430\n1.343637\n0.436606\n00:06\n\n\n1\n1.231681\n0.954694\n0.281220\n00:06\n\n\n2\n0.940422\n0.836008\n0.250715\n00:06\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninterp.plot_top_losses(5, nrows=1, figsize=(17,4))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn this case, the model’s performance decreased a little, so we would run the script again and revalidate the data.\n\n\nTest Model\n\npd.read_csv(\"./data/sample_submission.csv\").head()\n\n\n\n\n\n\n\n\n\nImageId\nLabel\n\n\n\n\n0\n1\n0\n\n\n1\n2\n0\n\n\n2\n3\n0\n\n\n3\n4\n0\n\n\n4\n5\n0\n\n\n\n\n\n\n\n\n\ntest_dl = dls.test_dl(get_image_files(test_dir))\npreds_probs = learn.get_preds(dl=test_dl)[0]  # probs\n\n\n\n\n\n\n\n\n\npreds = preds_probs.max(axis=1).indices\nids = np.arange(1, preds.shape[0]+1)\nsubmit_df = pd.DataFrame(np.vstack((ids, preds)).T, columns=[\"ImageId\", \"Label\"])\n\n\nsubmit_df.to_csv(\"submission.csv\", index=False)\n\nWe only used 5% of the data for training and validation, to make it faster, so, after iterating this process enough to be confident of our data processing and validation methods, and our model’s architecture and hypeparameters, we would retrain and validate it on the whole dataset."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Pandas Tests\n\n\nBackup of tests with the Pandas data manipulation tool.\n\n\n\nTests\n\n\n\n\n\n\nAfonso Matoso Magalhães\n\n\n\n\n\n\n\n\n\n\n\n\nfastai: Image Classifier\n\n\nApplication of the fastai library to the MNIST dataset.\n\n\n\ndeep learning\n\n\nimage classification\n\n\n\n\n\n\nAfonso Matoso Magalhães\n\n\n\n\n\n\nNo matching items"
  }
]